head(spam.df[with(spam.df, order(-occurrence)),])
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
all.easyham <- sapply(easyham.docs[1:length(spam.docs)],
function(p) get.msg(file.path(easyham.path, p)))
easyham.tdm <- get.tdm(all.easyham)
easyham.matrix <- as.matrix(easyham.tdm)
easyham.counts <- rowSums(easyham.matrix)
easyham.df <- data.frame(cbind(names(easyham.counts), as.numeric(easyham.counts)), stringsAsFactors = FALSE)
names(easyham.df) <- c("term", "frequency")
easyham.df$frequency <- as.numeric(easyham.df$frequency)
easyham.occurrence <- sapply(1:nrow(easyham.matrix),
function(i)
{
length(which(easyham.matrix[i, ] > 0)) / ncol(easyham.matrix)
})
easyham.density <- easyham.df$frequency / sum(easyham.df$frequency)
easyham.df <- transform(easyham.df,
density = easyham.density,
occurrence = easyham.occurrence)
head(easyham.df[with(easyham.df, order(-occurrence)),])
classify.email <- function(path, training.df, prior=0.5, c=1e-6) {
#First three lines are similar to what was done previously, reading in the emails in the folder, create the document term matrix, and calculating frequencies
msg <- get.msg(path)
msg.tdm <- get.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
# Find intersections of words between the email and the training data. Calculates the intersection of subsets of a probability space. Comparisons are made row-wise, so that in the data frame case, intersect(A,B) is a data frame with those rows that are both in A and in B.
msg.match <- intersect(names(msg.freq), training.df$term)
#See Special Note below for more information
if(length(msg.match) < 1) {
return(prior*c^(length(msg.freq)))
}
else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c^(length(msg.freq)-length(msg.match)))
}
}
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[which(hardham.docs != "cmds")]
hardham.spamtest <- sapply(hardham.docs,function(p) classify.email(paste(hardham.path, p, sep=""),training.df=spam.df))
hardham.hamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep=""),training.df=easyham.df))
hardham.res <- ifelse(hardham.spamtest > hardham.hamtest, TRUE, FALSE)
summary(hardham.res)
easyham.docs <- dir(easyham2.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
easyham.spamtest <- sapply(easyham.docs,function(p) classify.email(paste(easyham.path, p, sep=""),training.df=spam.df))
easyham.docs <- dir(easyham2.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
easyham.spamtest <- sapply(easyham.docs,function(p) classify.email(paste(easyham2.path, p, sep=""),training.df=spam.df))
paste(easyham2.path, p, sep="")
paste(easyham2.path, sep="")
con <- file(easyham2.path, open="rt")
easyham.docs <- dir(easyham2.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
easyham.spamtest <- sapply(easyham.docs,function(p) classify.email(paste(easyham2.path, p, sep=""),training.df=spam.df))
knitr::opts_chunk$set(echo = TRUE)
suppressWarnings(expr)
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(ggplot2)
#Set the path variables to the emails
spam.path <- "Data/spam/"
spam2.path <- "Data/spam_2/"
easyham.path <- "Data/easy_ham/"
easyham2.path <- "Data/easy_ham_2"
hardham.path <- "Data/hard_ham/"
#This function reads in a path variable, makes a connection to a file, and reads in the text after a blank line in the email  The blank line separates the email body from the email header
get.msg <- function(path) {
con <- file(path, open="rt")
text <- readLines(con)
msg <- text[seq(which(text=="")[1]+1,length(text),1)]
#After the email is read in, the connection is closed and a string without line spacing is returned.
close(con)
return(paste(msg, collapse="\n"))
}
#Reads all of the spam messages in the spam folder, removing the cmds file
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs!="cmds")]
#Applies all of the spam into one file
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path,p,sep="")))
#This function returns a document term matrix of a corpus.  A corpus is a collection of text data.
get.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
#This list creates cleaning agents for the corpus by remocing stopwords, punctuation, numbers, and minimizing the frequency to at least 2
control <- list(stopwords=TRUE, removePunctuation=TRUE, removeNumbers=TRUE,
minDocFreq=2)
doc.dtm <- TermDocumentMatrix(doc.corpus, control)
return(doc.dtm)
}
spam.tdm <- get.tdm(all.spam)
spam.matrix <- as.matrix(spam.tdm)
spam.counts <- rowSums(spam.matrix)
spam.df <- data.frame(cbind(names(spam.counts),
as.numeric(spam.counts)), stringsAsFactors=FALSE)
names(spam.df) <- c("term","frequency")
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.df
spam.occurrence <- sapply(1:nrow(spam.matrix),
function(i) {length(which(spam.matrix[i,] > 0))/ncol(spam.matrix)})
spam.density <- spam.df$frequency/sum(spam.df$frequency)
spam.df <- transform(spam.df, density=spam.density,occurrence=spam.occurrence)
head(spam.df[with(spam.df, order(-occurrence)),])
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
all.easyham <- sapply(easyham.docs[1:length(spam.docs)],
function(p) get.msg(file.path(easyham.path, p)))
easyham.tdm <- get.tdm(all.easyham)
easyham.matrix <- as.matrix(easyham.tdm)
easyham.counts <- rowSums(easyham.matrix)
easyham.df <- data.frame(cbind(names(easyham.counts), as.numeric(easyham.counts)), stringsAsFactors = FALSE)
names(easyham.df) <- c("term", "frequency")
easyham.df$frequency <- as.numeric(easyham.df$frequency)
easyham.occurrence <- sapply(1:nrow(easyham.matrix),
function(i)
{
length(which(easyham.matrix[i, ] > 0)) / ncol(easyham.matrix)
})
easyham.density <- easyham.df$frequency / sum(easyham.df$frequency)
easyham.df <- transform(easyham.df,
density = easyham.density,
occurrence = easyham.occurrence)
head(easyham.df[with(easyham.df, order(-occurrence)),])
classify.email <- function(path, training.df, prior=0.5, c=1e-6) {
#First three lines are similar to what was done previously, reading in the emails in the folder, create the document term matrix, and calculating frequencies
msg <- get.msg(path)
msg.tdm <- get.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
# Find intersections of words between the email and the training data. Calculates the intersection of subsets of a probability space. Comparisons are made row-wise, so that in the data frame case, intersect(A,B) is a data frame with those rows that are both in A and in B.
msg.match <- intersect(names(msg.freq), training.df$term)
#See Special Note below for more information
if(length(msg.match) < 1) {
return(prior*c^(length(msg.freq)))
}
else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c^(length(msg.freq)-length(msg.match)))
}
}
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[which(hardham.docs != "cmds")]
hardham.spamtest <- sapply(hardham.docs,function(p) classify.email(paste(hardham.path, p, sep=""),training.df=spam.df))
hardham.hamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep=""),training.df=easyham.df))
hardham.res <- ifelse(hardham.spamtest > hardham.hamtest, TRUE, FALSE)
summary(hardham.res)
easyham.docs <- dir(easyham2.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
easyham.spamtest <- sapply(easyham.docs,function(p) classify.email(paste(easyham2.path, p, sep=""),training.df=spam.df))
setwd('C:/Users/jkhan/Documents/GitHub/DATA-607-Data-Acquisition-and-Management/Project Four')
knitr::opts_chunk$set(echo = TRUE)
suppressWarnings(expr)
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(ggplot2)
#Set the path variables to the emails
spam.path <- "Data/spam/"
spam2.path <- "Data/spam_2/"
easyham.path <- "Data/easy_ham/"
easyham2.path <- "Data/easy_ham_2"
hardham.path <- "Data/hard_ham/"
#This function reads in a path variable, makes a connection to a file, and reads in the text after a blank line in the email  The blank line separates the email body from the email header
get.msg <- function(path) {
con <- file(path, open="rt")
text <- readLines(con)
msg <- text[seq(which(text=="")[1]+1,length(text),1)]
#After the email is read in, the connection is closed and a string without line spacing is returned.
close(con)
return(paste(msg, collapse="\n"))
}
#Reads all of the spam messages in the spam folder, removing the cmds file
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs!="cmds")]
#Applies all of the spam into one file
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path,p,sep="")))
#This function returns a document term matrix of a corpus.  A corpus is a collection of text data.
get.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
#This list creates cleaning agents for the corpus by remocing stopwords, punctuation, numbers, and minimizing the frequency to at least 2
control <- list(stopwords=TRUE, removePunctuation=TRUE, removeNumbers=TRUE,
minDocFreq=2)
doc.dtm <- TermDocumentMatrix(doc.corpus, control)
return(doc.dtm)
}
spam.tdm <- get.tdm(all.spam)
spam.matrix <- as.matrix(spam.tdm)
spam.counts <- rowSums(spam.matrix)
spam.df <- data.frame(cbind(names(spam.counts),
as.numeric(spam.counts)), stringsAsFactors=FALSE)
names(spam.df) <- c("term","frequency")
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.df
spam.occurrence <- sapply(1:nrow(spam.matrix),
function(i) {length(which(spam.matrix[i,] > 0))/ncol(spam.matrix)})
spam.density <- spam.df$frequency/sum(spam.df$frequency)
spam.df <- transform(spam.df, density=spam.density,occurrence=spam.occurrence)
head(spam.df[with(spam.df, order(-occurrence)),])
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
all.easyham <- sapply(easyham.docs[1:length(spam.docs)],
function(p) get.msg(file.path(easyham.path, p)))
easyham.tdm <- get.tdm(all.easyham)
easyham.matrix <- as.matrix(easyham.tdm)
easyham.counts <- rowSums(easyham.matrix)
easyham.df <- data.frame(cbind(names(easyham.counts), as.numeric(easyham.counts)), stringsAsFactors = FALSE)
names(easyham.df) <- c("term", "frequency")
easyham.df$frequency <- as.numeric(easyham.df$frequency)
easyham.occurrence <- sapply(1:nrow(easyham.matrix),
function(i)
{
length(which(easyham.matrix[i, ] > 0)) / ncol(easyham.matrix)
})
easyham.density <- easyham.df$frequency / sum(easyham.df$frequency)
easyham.df <- transform(easyham.df,
density = easyham.density,
occurrence = easyham.occurrence)
head(easyham.df[with(easyham.df, order(-occurrence)),])
classify.email <- function(path, training.df, prior=0.5, c=1e-6) {
#First three lines are similar to what was done previously, reading in the emails in the folder, create the document term matrix, and calculating frequencies
msg <- get.msg(path)
msg.tdm <- get.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
# Find intersections of words between the email and the training data. Calculates the intersection of subsets of a probability space. Comparisons are made row-wise, so that in the data frame case, intersect(A,B) is a data frame with those rows that are both in A and in B.
msg.match <- intersect(names(msg.freq), training.df$term)
#See Special Note below for more information
if(length(msg.match) < 1) {
return(prior*c^(length(msg.freq)))
}
else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c^(length(msg.freq)-length(msg.match)))
}
}
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[which(hardham.docs != "cmds")]
hardham.spamtest <- sapply(hardham.docs,function(p) classify.email(paste(hardham.path, p, sep=""),training.df=spam.df))
hardham.hamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep=""),training.df=easyham.df))
hardham.res <- ifelse(hardham.spamtest > hardham.hamtest, TRUE, FALSE)
summary(hardham.res)
easyham.docs <- dir(easyham2.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
easyham.spamtest <- sapply(easyham.docs,function(p) classify.email(paste(easyham2.path, p, sep=""),training.df=spam.df))
easyham.docs <- dir(easyham2.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
# easyham.spamtest <- sapply(easyham.docs,function(p) classify.email(paste(easyham2.path, p, sep=""),training.df=spam.df))
#
# easyham.hamtest <- sapply(easyham.docs, function(p) classify.email(paste(easyham2.path, p, sep=""),training.df=easyham.df))
#
# easyham.res <- ifelse(easyham.spamtest > easyham.easytest, TRUE, FALSE)
#
# summary(easyham.res)
easyham.docs <- dir(easyham2.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
easyham.spamtest <- sapply(easyham.docs,function(p) classify.email(paste(easyham2.path, p, sep=""),training.df=spam.df))
easyham.docs <- dir(easyham2.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
#easyham.spamtest <- sapply(easyham.docs,function(p) classify.email(paste(easyham2.path, p, sep=""),training.df=spam.df))
#
# easyham.hamtest <- sapply(easyham.docs, function(p) classify.email(paste(easyham2.path, p, sep=""),training.df=easyham.df))
#
# easyham.res <- ifelse(easyham.spamtest > easyham.easytest, TRUE, FALSE)
#
# summary(easyham.res)
con <- file(easyham2.path, open="rt")
con <- file(hardham.path, open="rt")
suppressWarnings(expr)
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(ggplot2)
#Set the path variables to the emails
spam.path <- "Data/spam/"
spam2.path <- "/Data/spam_2/"
easyham.path <- "/Data/easy_ham/"
easyham2.path <- "/Data/easy_ham_2"
hardham.path <- "Data/hard_ham/"
#This function reads in a path variable, makes a connection to a file, and reads in the text after a blank line in the email  The blank line separates the email body from the email header
get.msg <- function(path) {
con <- file(path, open="rt")
text <- readLines(con)
msg <- text[seq(which(text=="")[1]+1,length(text),1)]
#After the email is read in, the connection is closed and a string without line spacing is returned.
close(con)
return(paste(msg, collapse="\n"))
}
#Reads all of the spam messages in the spam folder, removing the cmds file
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs!="cmds")]
#Applies all of the spam into one file
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path,p,sep="")))
#This function returns a document term matrix of a corpus.  A corpus is a collection of text data.
get.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
#This list creates cleaning agents for the corpus by remocing stopwords, punctuation, numbers, and minimizing the frequency to at least 2
control <- list(stopwords=TRUE, removePunctuation=TRUE, removeNumbers=TRUE,
minDocFreq=2)
doc.dtm <- TermDocumentMatrix(doc.corpus, control)
return(doc.dtm)
}
spam.tdm <- get.tdm(all.spam)
spam.matrix <- as.matrix(spam.tdm)
spam.counts <- rowSums(spam.matrix)
spam.df <- data.frame(cbind(names(spam.counts),
as.numeric(spam.counts)), stringsAsFactors=FALSE)
names(spam.df) <- c("term","frequency")
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.df
spam.occurrence <- sapply(1:nrow(spam.matrix),
function(i) {length(which(spam.matrix[i,] > 0))/ncol(spam.matrix)})
spam.density <- spam.df$frequency/sum(spam.df$frequency)
spam.df <- transform(spam.df, density=spam.density,occurrence=spam.occurrence)
head(spam.df[with(spam.df, order(-occurrence)),])
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
all.easyham <- sapply(easyham.docs[1:length(spam.docs)],
function(p) get.msg(file.path(easyham.path, p)))
#Set the path variables to the emails
spam.path <- "Data/spam/"
spam2.path <- "Data/spam_2/"
easyham.path <- "Data/easy_ham/"
easyham2.path <- "Data/easy_ham_2"
hardham.path <- "Data/hard_ham/"
knitr::opts_chunk$set(echo = TRUE)
suppressWarnings(expr)
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(ggplot2)
#Set the path variables to the emails
spam.path <- "Data/spam/"
spam2.path <- "Data/spam_2/"
easyham.path <- "Data/easy_ham/"
easyham2.path <- "Data/easy_ham_2"
hardham.path <- "Data/hard_ham/"
#This function reads in a path variable, makes a connection to a file, and reads in the text after a blank line in the email  The blank line separates the email body from the email header
get.msg <- function(path) {
con <- file(path, open="rt")
text <- readLines(con)
msg <- text[seq(which(text=="")[1]+1,length(text),1)]
#After the email is read in, the connection is closed and a string without line spacing is returned.
close(con)
return(paste(msg, collapse="\n"))
}
#Reads all of the spam messages in the spam folder, removing the cmds file
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs!="cmds")]
#Applies all of the spam into one file
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path,p,sep="")))
#This function returns a document term matrix of a corpus.  A corpus is a collection of text data.
get.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
#This list creates cleaning agents for the corpus by remocing stopwords, punctuation, numbers, and minimizing the frequency to at least 2
control <- list(stopwords=TRUE, removePunctuation=TRUE, removeNumbers=TRUE,
minDocFreq=2)
doc.dtm <- TermDocumentMatrix(doc.corpus, control)
return(doc.dtm)
}
spam.tdm <- get.tdm(all.spam)
spam.matrix <- as.matrix(spam.tdm)
spam.counts <- rowSums(spam.matrix)
spam.df <- data.frame(cbind(names(spam.counts),
as.numeric(spam.counts)), stringsAsFactors=FALSE)
names(spam.df) <- c("term","frequency")
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.df
spam.occurrence <- sapply(1:nrow(spam.matrix),
function(i) {length(which(spam.matrix[i,] > 0))/ncol(spam.matrix)})
spam.density <- spam.df$frequency/sum(spam.df$frequency)
spam.df <- transform(spam.df, density=spam.density,occurrence=spam.occurrence)
head(spam.df[with(spam.df, order(-occurrence)),])
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
all.easyham <- sapply(easyham.docs[1:length(spam.docs)],
function(p) get.msg(file.path(easyham.path, p)))
easyham.tdm <- get.tdm(all.easyham)
easyham.matrix <- as.matrix(easyham.tdm)
easyham.counts <- rowSums(easyham.matrix)
easyham.df <- data.frame(cbind(names(easyham.counts), as.numeric(easyham.counts)), stringsAsFactors = FALSE)
names(easyham.df) <- c("term", "frequency")
easyham.df$frequency <- as.numeric(easyham.df$frequency)
easyham.occurrence <- sapply(1:nrow(easyham.matrix),
function(i)
{
length(which(easyham.matrix[i, ] > 0)) / ncol(easyham.matrix)
})
easyham.density <- easyham.df$frequency / sum(easyham.df$frequency)
easyham.df <- transform(easyham.df,
density = easyham.density,
occurrence = easyham.occurrence)
head(easyham.df[with(easyham.df, order(-occurrence)),])
classify.email <- function(path, training.df, prior=0.5, c=1e-6) {
#First three lines are similar to what was done previously, reading in the emails in the folder, create the document term matrix, and calculating frequencies
msg <- get.msg(path)
msg.tdm <- get.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
# Find intersections of words between the email and the training data. Calculates the intersection of subsets of a probability space. Comparisons are made row-wise, so that in the data frame case, intersect(A,B) is a data frame with those rows that are both in A and in B.
msg.match <- intersect(names(msg.freq), training.df$term)
#See Special Note below for more information
if(length(msg.match) < 1) {
return(prior*c^(length(msg.freq)))
}
else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c^(length(msg.freq)-length(msg.match)))
}
}
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[which(hardham.docs != "cmds")]
hardham.spamtest <- sapply(hardham.docs,function(p) classify.email(paste(hardham.path, p, sep=""),training.df=spam.df))
hardham.hamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep=""),training.df=easyham.df))
hardham.res <- ifelse(hardham.spamtest > hardham.hamtest, TRUE, FALSE)
summary(hardham.res)
easyham.docs <- dir(easyham2.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
easyham.spamtest <- sapply(easyham.docs,function(p) classify.email(paste(easyham2.path, p, sep=""),training.df=spam.df))
easyham.docs <- dir(easyham2.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
easyham.spamtest <- sapply(easyham.docs,function(p) classify.email(paste(easyham.path, p, sep=""),training.df=spam.df))
knitr::opts_chunk$set(echo = TRUE)
library(RCurl)
library(XML)
library(stringr)
library(tm)
library(ggplot2)
#Set the path variables to the emails
spam.path <- "Data/spam/"
spam2.path <- "Data/spam_2/"
easyham.path <- "Data/easy_ham/"
easyham2.path <- "Data/easy_ham_2"
hardham.path <- "Data/hard_ham/"
#This function reads in a path variable, makes a connection to a file, and reads in the text after a blank line in the email  The blank line separates the email body from the email header
get.msg <- function(path) {
con <- file(path, open="rt")
text <- readLines(con)
msg <- text[seq(which(text=="")[1]+1,length(text),1)]
#After the email is read in, the connection is closed and a string without line spacing is returned.
close(con)
return(paste(msg, collapse="\n"))
}
#Reads all of the spam messages in the spam folder, removing the cmds file
spam.docs <- dir(spam.path)
spam.docs <- spam.docs[which(spam.docs!="cmds")]
#Applies all of the spam into one file
all.spam <- sapply(spam.docs, function(p) get.msg(paste(spam.path,p,sep="")))
#This function returns a document term matrix of a corpus.  A corpus is a collection of text data.
get.tdm <- function(doc.vec) {
doc.corpus <- Corpus(VectorSource(doc.vec))
#This list creates cleaning agents for the corpus by remocing stopwords, punctuation, numbers, and minimizing the frequency to at least 2
control <- list(stopwords=TRUE, removePunctuation=TRUE, removeNumbers=TRUE,
minDocFreq=2)
doc.dtm <- TermDocumentMatrix(doc.corpus, control)
return(doc.dtm)
}
spam.tdm <- get.tdm(all.spam)
spam.matrix <- as.matrix(spam.tdm)
spam.counts <- rowSums(spam.matrix)
spam.df <- data.frame(cbind(names(spam.counts),
as.numeric(spam.counts)), stringsAsFactors=FALSE)
names(spam.df) <- c("term","frequency")
spam.df$frequency <- as.numeric(spam.df$frequency)
spam.df
spam.occurrence <- sapply(1:nrow(spam.matrix),
function(i) {length(which(spam.matrix[i,] > 0))/ncol(spam.matrix)})
spam.density <- spam.df$frequency/sum(spam.df$frequency)
spam.df <- transform(spam.df, density=spam.density,occurrence=spam.occurrence)
head(spam.df[with(spam.df, order(-occurrence)),])
easyham.docs <- dir(easyham.path)
easyham.docs <- easyham.docs[which(easyham.docs != "cmds")]
all.easyham <- sapply(easyham.docs[1:length(spam.docs)],
function(p) get.msg(file.path(easyham.path, p)))
easyham.tdm <- get.tdm(all.easyham)
easyham.matrix <- as.matrix(easyham.tdm)
easyham.counts <- rowSums(easyham.matrix)
easyham.df <- data.frame(cbind(names(easyham.counts), as.numeric(easyham.counts)), stringsAsFactors = FALSE)
names(easyham.df) <- c("term", "frequency")
easyham.df$frequency <- as.numeric(easyham.df$frequency)
easyham.occurrence <- sapply(1:nrow(easyham.matrix),
function(i)
{
length(which(easyham.matrix[i, ] > 0)) / ncol(easyham.matrix)
})
easyham.density <- easyham.df$frequency / sum(easyham.df$frequency)
easyham.df <- transform(easyham.df,
density = easyham.density,
occurrence = easyham.occurrence)
head(easyham.df[with(easyham.df, order(-occurrence)),])
classify.email <- function(path, training.df, prior=0.5, c=1e-6) {
#First three lines are similar to what was done previously, reading in the emails in the folder, create the document term matrix, and calculating frequencies
msg <- get.msg(path)
msg.tdm <- get.tdm(msg)
msg.freq <- rowSums(as.matrix(msg.tdm))
# Find intersections of words between the email and the training data. Calculates the intersection of subsets of a probability space. Comparisons are made row-wise, so that in the data frame case, intersect(A,B) is a data frame with those rows that are both in A and in B.
msg.match <- intersect(names(msg.freq), training.df$term)
#See Special Note below for more information
if(length(msg.match) < 1) {
return(prior*c^(length(msg.freq)))
}
else {
match.probs <- training.df$occurrence[match(msg.match, training.df$term)]
return(prior * prod(match.probs) * c^(length(msg.freq)-length(msg.match)))
}
}
hardham.docs <- dir(hardham.path)
hardham.docs <- hardham.docs[which(hardham.docs != "cmds")]
hardham.spamtest <- sapply(hardham.docs,function(p) classify.email(paste(hardham.path, p, sep=""),training.df=spam.df))
hardham.hamtest <- sapply(hardham.docs, function(p) classify.email(paste(hardham.path, p, sep=""),training.df=easyham.df))
hardham.res <- ifelse(hardham.spamtest > hardham.hamtest, TRUE, FALSE)
summary(hardham.res)
